{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please complete the following sections sequentially to complete this assignment.\n",
    "\n",
    "##### <span style=\"color:red\">Note: You can create as many code or markdown cells as you deem necessary to answer each question. However, please leave the problems unchanged. We will evaluate your solutions by executing your code sequentially.</span> \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Within the expansion of the Internet and Web, there has also been a growing interest in online articles and reviews, which allows an easy and fast spread of information worldwide. Thus, predicting the popularity of online news has become a trend. Popularity is often measured by considering the number of interactions in the Web and social networks (e.g., number of shares, likes, and comments). Predicting such popularity is valuable for advertisers, authors, content providers, and even activists/politicians (e.g., to understand or influence public opinion). In this assignment, we use a news popularity dataset utilized by Fernandes et al. (2015) based on the articles published by [Mashable](https://mashable.com/) from January 7, 2013, to January 7, 2015.**\n",
    "\n",
    "**<span style=\"color:red\">The objective of this assignment is to predict the number of times a news article is shared. </span> The assignment's dataset is included in the homework's zipped folder. Table below has the description of each variable in the dataset.**\n",
    "\n",
    "| Variable                      | Description                                                                       |\n",
    "|-------------------------------|-----------------------------------------------------------------------------------|\n",
    "| url                           | URL of the article (non-predictive)                                               |\n",
    "| timedelta                     | Days between the article publication and the dataset acquisition (non-predictive) |\n",
    "| n_tokens_title                | Number of words in the title                                                      |\n",
    "| n_tokens_content              | Number of words in the content                                                    |\n",
    "| n_unique_tokens               | Rate of unique words in the content                                               |\n",
    "| n_non_stop_words              | Rate of non-stop words in the content                                             |\n",
    "| n_non_stop_unique_tokens      | Rate of unique non-stop words in the content                                      |\n",
    "| num_hrefs                     | Number of links                                                                   |\n",
    "| num_self_hrefs                | Number of links to other articles published by Mashable                           |\n",
    "| num_imgs                      | Number of images                                                                  |\n",
    "| num_videos                    | Number of videos                                                                  |\n",
    "| average_token_length          | Average length of the words in the content                                        |\n",
    "| num_keywords                  | Number of keywords in the metadata                                                |\n",
    "| data_channel_is_lifestyle     | Is data channel 'Lifestyle'?                                                      |\n",
    "| data_channel_is_entertainment | Is data channel 'Entertainment'?                                                  |\n",
    "| data_channel_is_bus           | Is data channel 'Business'?                                                       |\n",
    "| data_channel_is_socmed        | Is data channel 'Social Media'?                                                   |\n",
    "| data_channel_is_tech          | Is data channel 'Tech'?                                                           |\n",
    "| data_channel_is_world         | Is data channel 'World'?                                                          |\n",
    "| kw_min_min                    | Min. shares of the Worst keyword in the article                                   |\n",
    "| kw_max_min                    | Max. shares of the Worst keyword in the article                                   |\n",
    "| kw_avg_min                    | Avg. shares of the Worst keyword in the article                                   |\n",
    "| kw_min_max                    | Min. shares of the best keyword in the article                                    |\n",
    "| kw_max_max                    | Max. shares of the best keyword in the article                                    |\n",
    "| kw_avg_max                    | Avg. shares of the best keyword in the article                                    |\n",
    "| kw_min_avg                    | Min. shares of the average keyword in the article                                 |\n",
    "| kw_max_avg                    | Max. shares of the average keyword in the article                                 |\n",
    "| kw_avg_avg                    | Avg. shares of the average keyword in the article                                 |\n",
    "| self_reference_min_shares     | Min. shares of referenced articles in Mashable                                    |\n",
    "| self_reference_max_shares     | Max. shares of referenced articles in Mashable                                    |\n",
    "| self_reference_avg_sharess    | Avg. shares of referenced articles in Mashable                                    |\n",
    "| weekday_is_monday             | Was the article published on a Monday?                                            |\n",
    "| weekday_is_tuesday            | Was the article published on a Tuesday?                                           |\n",
    "| weekday_is_wednesday          | Was the article published on a Wednesday?                                         |\n",
    "| weekday_is_thursday           | Was the article published on a Thursday?                                          |\n",
    "| weekday_is_friday             | Was the article published on a Friday?                                            |\n",
    "| weekday_is_saturday           | Was the article published on a Saturday?                                          |\n",
    "| weekday_is_sunday             | Was the article published on a Sunday?                                            |\n",
    "| is_weekend                    | Was the article published on the weekend?                                         |\n",
    "| LDA_00                        | Closeness to LDA topic 0                                                          |\n",
    "| LDA_01                        | Closeness to LDA topic 1                                                          |\n",
    "| LDA_02                        | Closeness to LDA topic 2                                                          |\n",
    "| LDA_03                        | Closeness to LDA topic 3                                                          |\n",
    "| LDA_04                        | Closeness to LDA topic 4                                                          |\n",
    "| global_subjectivity           | Text subjectivity                                                                 |\n",
    "| global_sentiment_polarity     | Text sentiment polarity                                                           |\n",
    "| global_rate_positive_words    | Rate of positive words in the content                                             |\n",
    "| global_rate_negative_words    | Rate of negative words in the content                                             |\n",
    "| rate_positive_words           | Rate of positive words among non-neutral tokens                                   |\n",
    "| rate_negative_words           | Rate of negative words among non-neutral tokens                                   |\n",
    "| avg_positive_polarity         | Avg. polarity of positive words                                                   |\n",
    "| min_positive_polarity         | Min. polarity of positive words                                                   |\n",
    "| max_positive_polarity         | Max. polarity of positive words                                                   |\n",
    "| avg_negative_polarity         | Avg. polarity of negative words                                                   |\n",
    "| min_negative_polarity         | Min. polarity of negative words                                                   |\n",
    "| max_negative_polarity         | Max. polarity of negative words                                                   |\n",
    "| title_subjectivity            | Title subjectivity                                                                |\n",
    "| title_sentiment_polarity      | Title polarity                                                                    |\n",
    "| abs_title_subjectivity        | Absolute subjectivity level                                                       |\n",
    "| abs_title_sentiment_polarity  | Absolute polarity level                                                           |\n",
    "| **shares (Target)**           | **Number of shares**                                                              |\n",
    "| popular (DO NOT USE)          | whether the article is popular (yes/no)                                           |\n",
    "\n",
    "Reference:\n",
    "\n",
    "Fernandes, K., Vinagre, P., & Cortez, P. (2015, September). A proactive intelligent decision support system for predicting the popularity of online news. In Portuguese Conference on Artificial Intelligence (pp. 535-546). Springer, Cham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Import Packages and Read the Data\n",
    "\n",
    "**Before starting the assignment, import all necessary libraries and read the dataset into the Python environment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, RocCurveDisplay, auc, r2_score, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import tree\n",
    "\n",
    "from pydotplus import graph_from_dot_data\n",
    "\n",
    "# Generate a unique color\n",
    "def generate_unique_color():\n",
    "    color = \"#\" + ''.join([random.choice('0123456789ABCDEF') for _ in range(6)])\n",
    "    return color\n",
    "\n",
    "df = pd.read_csv('online_news_popularity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Introduction to Regression Trees\n",
    "\n",
    "**1- Watch this [video](https://ohiouniversity.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=403295c8-1da1-4c46-a3ed-acd9002069dd) for an intorudction to regression trees.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2- Briefly describe how regression trees work. (10 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Regression trees:** Work by recursively partitioning the input space into smaller regions based on the values of input features. The tree is built by selecting the feature and split point that minimizes the sum of squared errors within each region. The resulting tree can be used to make predictions by traversing the tree from the root to a leaf node, where the predicted value is the average of the training samples within that leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3- What are the similarities of classification and regression tree models? (10 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification and regression tree models share similarities in their decision-making process, use of splitting criteria, hierarchical structure, predictive capabilities, and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4- What are the differences of classification and regression tree models? (10 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification tree models are used for predicting categorical or discrete outcomes, while regression tree models are used for predicting continuous or numeric outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5- How is MSE used in regression trees? (10 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Squared Error (MSE) is used as a metric to evaluate the quality of splits during the tree-building process. MSE measures the average squared difference between the predicted and actual values of the target variable. The tree algorithm aims to minimize the MSE by selecting the splitting criteria that leads to the smallest MSE in each node, ultimately producing a regression tree with the least overall prediction error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6- Why does overfitting happen in regression trees? and how can it be avoided? (10 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overfitting in regression trees occurs when the model becomes too complex and captures noise or random fluctuations in the training data, leading to poor performance on unseen data. To avoid overfitting, techniques such as pruning, , cross-validation, and feature selection can be used to improve the model's generalization and prevent the capture of irrelevant details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Regression Trees in Python\n",
    "\n",
    "**7- Watch this [video](https://ohiouniversity.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=bd5b0d61-6837-4d54-b2b4-acd9002071b8) to learn about implementing regression trees in Python. The video's dataset is included in the assignment zipped folder, in case you want to replicate the codes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8- Check if there are any missing values and take care of them if needed. (5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                             0\n",
       "timedelta                       0\n",
       "n_tokens_title                  0\n",
       "n_tokens_content                0\n",
       "n_unique_tokens                 0\n",
       "n_non_stop_words                0\n",
       "n_non_stop_unique_tokens        0\n",
       "num_hrefs                       0\n",
       "num_self_hrefs                  0\n",
       "num_imgs                        0\n",
       "num_videos                      0\n",
       "average_token_length            0\n",
       "num_keywords                    0\n",
       "channel                         0\n",
       "kw_min_min                      0\n",
       "kw_max_min                      0\n",
       "kw_avg_min                      0\n",
       "kw_min_max                      0\n",
       "kw_max_max                      0\n",
       "kw_avg_max                      0\n",
       "kw_min_avg                      0\n",
       "kw_max_avg                      0\n",
       "kw_avg_avg                      0\n",
       "self_reference_min_shares       0\n",
       "self_reference_max_shares       0\n",
       "self_reference_avg_sharess      0\n",
       "weekday                         0\n",
       "is_weekend                      0\n",
       "LDA_00                          0\n",
       "LDA_01                          0\n",
       "LDA_02                          0\n",
       "LDA_03                          0\n",
       "LDA_04                          0\n",
       "global_subjectivity             0\n",
       "global_sentiment_polarity       0\n",
       "global_rate_positive_words      0\n",
       "global_rate_negative_words      0\n",
       "rate_positive_words             0\n",
       "rate_negative_words             0\n",
       "avg_positive_polarity           0\n",
       "min_positive_polarity           0\n",
       "max_positive_polarity           0\n",
       "avg_negative_polarity           0\n",
       "min_negative_polarity           0\n",
       "max_negative_polarity           0\n",
       "title_subjectivity              0\n",
       "title_sentiment_polarity        0\n",
       "abs_title_subjectivity          0\n",
       "abs_title_sentiment_polarity    0\n",
       "shares                          0\n",
       "popular                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9- Detect and eliminate the outliers of these variables: ```['LDA_02', 'LDA_03', 'LDA_04']``` (10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['LDA_02', 'LDA_03', 'LDA_04']\n",
    "sns.boxplot(data=df[columns])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39644, 51)\n",
      "(36103, 51)\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "var_list = ['LDA_02', 'LDA_03', 'LDA_04']\n",
    "\n",
    "for var in var_list:\n",
    "    iqr = df_clean[var].quantile(0.75) - df_clean[var].quantile(0.25)\n",
    "    if not np.isnan(iqr):\n",
    "        ub = df_clean[var].quantile(0.75) + 1.5 * iqr\n",
    "        lb = df_clean[var].quantile(0.25) - 1.5 * iqr\n",
    "        df_clean = df_clean[(df_clean[var] >= lb) & (df_clean[var] <= ub)]\n",
    "\n",
    "print(df.shape)        \n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10- Dummy encode all categorical variables. (5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>popular</th>\n",
       "      <th>channel_entertainment</th>\n",
       "      <th>channel_lifestyle</th>\n",
       "      <th>channel_other</th>\n",
       "      <th>channel_social_media</th>\n",
       "      <th>channel_tech</th>\n",
       "      <th>channel_world</th>\n",
       "      <th>weekday_monday</th>\n",
       "      <th>weekday_saturday</th>\n",
       "      <th>weekday_sunday</th>\n",
       "      <th>weekday_thursday</th>\n",
       "      <th>weekday_tuesday</th>\n",
       "      <th>weekday_wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731</td>\n",
       "      <td>12</td>\n",
       "      <td>219</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731</td>\n",
       "      <td>9</td>\n",
       "      <td>255</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799756</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.050096</td>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.341246</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731</td>\n",
       "      <td>9</td>\n",
       "      <td>211</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217792</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033351</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.682188</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731</td>\n",
       "      <td>9</td>\n",
       "      <td>531</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.494651</td>\n",
       "      <td>0.028905</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.429850</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731</td>\n",
       "      <td>13</td>\n",
       "      <td>1072</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>3151.157895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>0.028794</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.281003</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...        731   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...        731   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...        731   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...        731   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/        731   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0              12               219         0.663594               1.0   \n",
       "1               9               255         0.604743               1.0   \n",
       "2               9               211         0.575130               1.0   \n",
       "3               9               531         0.503788               1.0   \n",
       "4              13              1072         0.415646               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.815385          4               2         1           0   \n",
       "1                  0.791946          3               1         1           0   \n",
       "2                  0.663866          3               1         1           0   \n",
       "3                  0.665635          9               0         1           0   \n",
       "4                  0.540890         19              19        20           0   \n",
       "\n",
       "   average_token_length  num_keywords  kw_min_min  kw_max_min  kw_avg_min  \\\n",
       "0              4.680365             5           0         0.0         0.0   \n",
       "1              4.913725             4           0         0.0         0.0   \n",
       "2              4.393365             6           0         0.0         0.0   \n",
       "3              4.404896             7           0         0.0         0.0   \n",
       "4              4.682836             7           0         0.0         0.0   \n",
       "\n",
       "   kw_min_max  kw_max_max  kw_avg_max  kw_min_avg  kw_max_avg  kw_avg_avg  \\\n",
       "0           0           0         0.0         0.0         0.0         0.0   \n",
       "1           0           0         0.0         0.0         0.0         0.0   \n",
       "2           0           0         0.0         0.0         0.0         0.0   \n",
       "3           0           0         0.0         0.0         0.0         0.0   \n",
       "4           0           0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   self_reference_min_shares  self_reference_max_shares  \\\n",
       "0                      496.0                      496.0   \n",
       "1                        0.0                        0.0   \n",
       "2                      918.0                      918.0   \n",
       "3                        0.0                        0.0   \n",
       "4                      545.0                    16000.0   \n",
       "\n",
       "   self_reference_avg_sharess  is_weekend    LDA_00    LDA_01    LDA_02  \\\n",
       "0                  496.000000           0  0.500331  0.378279  0.040005   \n",
       "1                    0.000000           0  0.799756  0.050047  0.050096   \n",
       "2                  918.000000           0  0.217792  0.033334  0.033351   \n",
       "3                    0.000000           0  0.028573  0.419300  0.494651   \n",
       "4                 3151.157895           0  0.028633  0.028794  0.028575   \n",
       "\n",
       "     LDA_03    LDA_04  global_subjectivity  global_sentiment_polarity  \\\n",
       "0  0.041263  0.040123             0.521617                   0.092562   \n",
       "1  0.050101  0.050001             0.341246                   0.148948   \n",
       "2  0.033334  0.682188             0.702222                   0.323333   \n",
       "3  0.028905  0.028572             0.429850                   0.100705   \n",
       "4  0.028572  0.885427             0.513502                   0.281003   \n",
       "\n",
       "   global_rate_positive_words  global_rate_negative_words  \\\n",
       "0                    0.045662                    0.013699   \n",
       "1                    0.043137                    0.015686   \n",
       "2                    0.056872                    0.009479   \n",
       "3                    0.041431                    0.020716   \n",
       "4                    0.074627                    0.012127   \n",
       "\n",
       "   rate_positive_words  rate_negative_words  avg_positive_polarity  \\\n",
       "0             0.769231             0.230769               0.378636   \n",
       "1             0.733333             0.266667               0.286915   \n",
       "2             0.857143             0.142857               0.495833   \n",
       "3             0.666667             0.333333               0.385965   \n",
       "4             0.860215             0.139785               0.411127   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.100000                    0.7              -0.350000   \n",
       "1               0.033333                    0.7              -0.118750   \n",
       "2               0.100000                    1.0              -0.466667   \n",
       "3               0.136364                    0.8              -0.369697   \n",
       "4               0.033333                    1.0              -0.220192   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                 -0.600              -0.200000            0.500000   \n",
       "1                 -0.125              -0.100000            0.000000   \n",
       "2                 -0.800              -0.133333            0.000000   \n",
       "3                 -0.600              -0.166667            0.000000   \n",
       "4                 -0.500              -0.050000            0.454545   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                 -0.187500                0.000000   \n",
       "1                  0.000000                0.500000   \n",
       "2                  0.000000                0.500000   \n",
       "3                  0.000000                0.500000   \n",
       "4                  0.136364                0.045455   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares popular  channel_entertainment  \\\n",
       "0                      0.187500     593      no                      1   \n",
       "1                      0.000000     711      no                      0   \n",
       "2                      0.000000    1500     yes                      0   \n",
       "3                      0.000000    1200      no                      1   \n",
       "4                      0.136364     505      no                      0   \n",
       "\n",
       "   channel_lifestyle  channel_other  channel_social_media  channel_tech  \\\n",
       "0                  0              0                     0             0   \n",
       "1                  0              0                     0             0   \n",
       "2                  0              0                     0             0   \n",
       "3                  0              0                     0             0   \n",
       "4                  0              0                     0             1   \n",
       "\n",
       "   channel_world  weekday_monday  weekday_saturday  weekday_sunday  \\\n",
       "0              0               1                 0               0   \n",
       "1              0               1                 0               0   \n",
       "2              0               1                 0               0   \n",
       "3              0               1                 0               0   \n",
       "4              0               1                 0               0   \n",
       "\n",
       "   weekday_thursday  weekday_tuesday  weekday_wednesday  \n",
       "0                 0                0                  0  \n",
       "1                 0                0                  0  \n",
       "2                 0                0                  0  \n",
       "3                 0                0                  0  \n",
       "4                 0                0                  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = ['channel', 'weekday']\n",
    "df1 = pd.get_dummies(df_clean, columns=cats, drop_first=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11- Partition the data (Consider 80% of the data as train). (5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_list = ['n_tokens_title', 'n_tokens_content',\n",
    "               'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens',\n",
    "               'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos',\n",
    "               'average_token_length', 'num_keywords', 'kw_min_min', 'kw_max_min',\n",
    "               'kw_avg_min', 'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg',\n",
    "               'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares',\n",
    "               'self_reference_max_shares', 'self_reference_avg_sharess', 'is_weekend',\n",
    "               'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
    "               'global_sentiment_polarity', 'global_rate_positive_words',\n",
    "               'global_rate_negative_words', 'rate_positive_words',\n",
    "               'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
    "               'max_positive_polarity', 'avg_negative_polarity',\n",
    "               'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
    "               'title_sentiment_polarity', 'abs_title_subjectivity',\n",
    "               'abs_title_sentiment_polarity',\n",
    "               'channel_entertainment', 'channel_lifestyle', 'channel_other',\n",
    "               'channel_social_media', 'channel_tech', 'channel_world',\n",
    "               'weekday_monday', 'weekday_saturday', 'weekday_sunday',\n",
    "               'weekday_thursday', 'weekday_tuesday', 'weekday_wednesday']\n",
    "\n",
    "X = df1[var_list]\n",
    "y = df1['shares']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12- Using proper input variables, build a regression tree that predicts the number of times a news article is shared. After building your model, do the following: (30 pts)**\n",
    "* __Calculate the $ r^2 $ and MSE of the model on the train data,__\n",
    "* __Visulaize the tree,__\n",
    "* __Set the parameters of the regression tree such that it does not overfit the data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2: 69.66%\n",
      "train MSE: 4643085029.94%\n"
     ]
    }
   ],
   "source": [
    "# ways of pruning classification tree: dec_tree = tree.DecisionTreeClassifier(min_samples_split=5000, max_leaf_nodes=10, ccp_alpha=0.005) can be used to set restrictions on the splits of the data\n",
    "dec_tree = tree.DecisionTreeRegressor(max_leaf_nodes=100)\n",
    "dec_tree.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_train_hat = dec_tree.predict(X_train)\n",
    "\n",
    "print('train r2:', \"{:.2f}%\".format(r2_score(y_train, y_train_hat)*100))\n",
    "print('train MSE:', \"{:.2f}%\".format(mean_squared_error(y_train, y_train_hat)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- kw_avg_avg <= 3640.96\n",
      "|   |--- self_reference_avg_sharess <= 5904.64\n",
      "|   |   |--- kw_max_avg <= 3853.02\n",
      "|   |   |   |--- value: [2081.58]\n",
      "|   |   |--- kw_max_avg >  3853.02\n",
      "|   |   |   |--- LDA_01 <= 0.92\n",
      "|   |   |   |   |--- value: [2884.57]\n",
      "|   |   |   |--- LDA_01 >  0.92\n",
      "|   |   |   |   |--- n_tokens_content <= 2532.50\n",
      "|   |   |   |   |   |--- average_token_length <= 4.31\n",
      "|   |   |   |   |   |   |--- avg_positive_polarity <= 0.41\n",
      "|   |   |   |   |   |   |   |--- value: [87600.00]\n",
      "|   |   |   |   |   |   |--- avg_positive_polarity >  0.41\n",
      "|   |   |   |   |   |   |   |--- value: [20950.00]\n",
      "|   |   |   |   |   |--- average_token_length >  4.31\n",
      "|   |   |   |   |   |   |--- value: [1384.56]\n",
      "|   |   |   |   |--- n_tokens_content >  2532.50\n",
      "|   |   |   |   |   |--- value: [210300.00]\n",
      "|   |--- self_reference_avg_sharess >  5904.64\n",
      "|   |   |--- n_unique_tokens <= 0.24\n",
      "|   |   |   |--- global_subjectivity <= 0.41\n",
      "|   |   |   |   |--- value: [10479.00]\n",
      "|   |   |   |--- global_subjectivity >  0.41\n",
      "|   |   |   |   |--- value: [663600.00]\n",
      "|   |   |--- n_unique_tokens >  0.24\n",
      "|   |   |   |--- kw_max_avg <= 3971.78\n",
      "|   |   |   |   |--- value: [2938.54]\n",
      "|   |   |   |--- kw_max_avg >  3971.78\n",
      "|   |   |   |   |--- kw_max_avg <= 3972.59\n",
      "|   |   |   |   |   |--- value: [98700.00]\n",
      "|   |   |   |   |--- kw_max_avg >  3972.59\n",
      "|   |   |   |   |   |--- avg_negative_polarity <= -0.42\n",
      "|   |   |   |   |   |   |--- min_negative_polarity <= -0.47\n",
      "|   |   |   |   |   |   |   |--- LDA_00 <= 0.87\n",
      "|   |   |   |   |   |   |   |   |--- kw_avg_avg <= 1913.22\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [138700.00]\n",
      "|   |   |   |   |   |   |   |   |--- kw_avg_avg >  1913.22\n",
      "|   |   |   |   |   |   |   |   |   |--- avg_negative_polarity <= -0.42\n",
      "|   |   |   |   |   |   |   |   |   |   |--- n_non_stop_unique_tokens <= 0.93\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- n_non_stop_unique_tokens >  0.93\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- avg_negative_polarity >  -0.42\n",
      "|   |   |   |   |   |   |   |   |   |   |--- value: [96000.00]\n",
      "|   |   |   |   |   |   |   |--- LDA_00 >  0.87\n",
      "|   |   |   |   |   |   |   |   |--- n_tokens_title <= 10.50\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [1948.00]\n",
      "|   |   |   |   |   |   |   |   |--- n_tokens_title >  10.50\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [298400.00]\n",
      "|   |   |   |   |   |   |--- min_negative_polarity >  -0.47\n",
      "|   |   |   |   |   |   |   |--- self_reference_max_shares <= 39250.00\n",
      "|   |   |   |   |   |   |   |   |--- value: [284700.00]\n",
      "|   |   |   |   |   |   |   |--- self_reference_max_shares >  39250.00\n",
      "|   |   |   |   |   |   |   |   |--- value: [3700.00]\n",
      "|   |   |   |   |   |--- avg_negative_polarity >  -0.42\n",
      "|   |   |   |   |   |   |--- global_subjectivity <= 0.70\n",
      "|   |   |   |   |   |   |   |--- n_tokens_content <= 3720.00\n",
      "|   |   |   |   |   |   |   |   |--- value: [4318.40]\n",
      "|   |   |   |   |   |   |   |--- n_tokens_content >  3720.00\n",
      "|   |   |   |   |   |   |   |   |--- num_keywords <= 7.00\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [856.00]\n",
      "|   |   |   |   |   |   |   |   |--- num_keywords >  7.00\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [81200.00]\n",
      "|   |   |   |   |   |   |--- global_subjectivity >  0.70\n",
      "|   |   |   |   |   |   |   |--- max_negative_polarity <= -0.15\n",
      "|   |   |   |   |   |   |   |   |--- value: [143100.00]\n",
      "|   |   |   |   |   |   |   |--- max_negative_polarity >  -0.15\n",
      "|   |   |   |   |   |   |   |   |--- value: [2000.00]\n",
      "|--- kw_avg_avg >  3640.96\n",
      "|   |--- self_reference_min_shares <= 265900.00\n",
      "|   |   |--- self_reference_avg_sharess <= 4790.00\n",
      "|   |   |   |--- kw_avg_avg <= 4694.72\n",
      "|   |   |   |   |--- value: [3819.46]\n",
      "|   |   |   |--- kw_avg_avg >  4694.72\n",
      "|   |   |   |   |--- n_tokens_title <= 15.50\n",
      "|   |   |   |   |   |--- value: [5609.93]\n",
      "|   |   |   |   |--- n_tokens_title >  15.50\n",
      "|   |   |   |   |   |--- weekday_tuesday <= 0.50\n",
      "|   |   |   |   |   |   |--- value: [6339.25]\n",
      "|   |   |   |   |   |--- weekday_tuesday >  0.50\n",
      "|   |   |   |   |   |   |--- kw_min_avg <= 3192.56\n",
      "|   |   |   |   |   |   |   |--- value: [11212.00]\n",
      "|   |   |   |   |   |   |--- kw_min_avg >  3192.56\n",
      "|   |   |   |   |   |   |   |--- value: [211600.00]\n",
      "|   |   |--- self_reference_avg_sharess >  4790.00\n",
      "|   |   |   |--- kw_avg_avg <= 3648.39\n",
      "|   |   |   |   |--- kw_avg_avg <= 3647.68\n",
      "|   |   |   |   |   |--- rate_positive_words <= 0.55\n",
      "|   |   |   |   |   |   |--- value: [79700.00]\n",
      "|   |   |   |   |   |--- rate_positive_words >  0.55\n",
      "|   |   |   |   |   |   |--- value: [4918.75]\n",
      "|   |   |   |   |--- kw_avg_avg >  3647.68\n",
      "|   |   |   |   |   |--- value: [441000.00]\n",
      "|   |   |   |--- kw_avg_avg >  3648.39\n",
      "|   |   |   |   |--- kw_avg_avg <= 4999.74\n",
      "|   |   |   |   |   |--- num_hrefs <= 27.50\n",
      "|   |   |   |   |   |   |--- self_reference_min_shares <= 100000.00\n",
      "|   |   |   |   |   |   |   |--- global_subjectivity <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- value: [4120.12]\n",
      "|   |   |   |   |   |   |   |--- global_subjectivity >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- rate_negative_words <= 0.38\n",
      "|   |   |   |   |   |   |   |   |   |--- LDA_01 <= 0.78\n",
      "|   |   |   |   |   |   |   |   |   |   |--- value: [5080.98]\n",
      "|   |   |   |   |   |   |   |   |   |--- LDA_01 >  0.78\n",
      "|   |   |   |   |   |   |   |   |   |   |--- kw_min_avg <= 3223.83\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [8001.31]\n",
      "|   |   |   |   |   |   |   |   |   |   |--- kw_min_avg >  3223.83\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [49733.33]\n",
      "|   |   |   |   |   |   |   |   |--- rate_negative_words >  0.38\n",
      "|   |   |   |   |   |   |   |   |   |--- n_tokens_title <= 15.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- avg_negative_polarity <= -0.66\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- avg_negative_polarity >  -0.66\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |--- n_tokens_title >  15.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- LDA_02 <= 0.02\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [133700.00]\n",
      "|   |   |   |   |   |   |   |   |   |   |--- LDA_02 >  0.02\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [1703.00]\n",
      "|   |   |   |   |   |   |--- self_reference_min_shares >  100000.00\n",
      "|   |   |   |   |   |   |   |--- n_unique_tokens <= 0.67\n",
      "|   |   |   |   |   |   |   |   |--- value: [4230.33]\n",
      "|   |   |   |   |   |   |   |--- n_unique_tokens >  0.67\n",
      "|   |   |   |   |   |   |   |   |--- value: [205600.00]\n",
      "|   |   |   |   |   |--- num_hrefs >  27.50\n",
      "|   |   |   |   |   |   |--- kw_max_avg <= 5124.38\n",
      "|   |   |   |   |   |   |   |--- LDA_00 <= 0.04\n",
      "|   |   |   |   |   |   |   |   |--- value: [843300.00]\n",
      "|   |   |   |   |   |   |   |--- LDA_00 >  0.04\n",
      "|   |   |   |   |   |   |   |   |--- title_sentiment_polarity <= 0.70\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [4662.50]\n",
      "|   |   |   |   |   |   |   |   |--- title_sentiment_polarity >  0.70\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [57000.00]\n",
      "|   |   |   |   |   |   |--- kw_max_avg >  5124.38\n",
      "|   |   |   |   |   |   |   |--- LDA_03 <= 0.02\n",
      "|   |   |   |   |   |   |   |   |--- rate_negative_words <= 0.30\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [88500.00]\n",
      "|   |   |   |   |   |   |   |   |--- rate_negative_words >  0.30\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [3200.00]\n",
      "|   |   |   |   |   |   |   |--- LDA_03 >  0.02\n",
      "|   |   |   |   |   |   |   |   |--- min_positive_polarity <= 0.06\n",
      "|   |   |   |   |   |   |   |   |   |--- title_sentiment_polarity <= -0.67\n",
      "|   |   |   |   |   |   |   |   |   |   |--- kw_max_min <= 526.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [6200.00]\n",
      "|   |   |   |   |   |   |   |   |   |   |--- kw_max_min >  526.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [112600.00]\n",
      "|   |   |   |   |   |   |   |   |   |--- title_sentiment_polarity >  -0.67\n",
      "|   |   |   |   |   |   |   |   |   |   |--- num_imgs <= 37.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- num_imgs >  37.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |--- min_positive_polarity >  0.06\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [4295.61]\n",
      "|   |   |   |   |--- kw_avg_avg >  4999.74\n",
      "|   |   |   |   |   |--- self_reference_min_shares <= 709.00\n",
      "|   |   |   |   |   |   |--- kw_max_max <= 654150.00\n",
      "|   |   |   |   |   |   |   |--- global_rate_negative_words <= 0.02\n",
      "|   |   |   |   |   |   |   |   |--- value: [3900.00]\n",
      "|   |   |   |   |   |   |   |--- global_rate_negative_words >  0.02\n",
      "|   |   |   |   |   |   |   |   |--- value: [690400.00]\n",
      "|   |   |   |   |   |   |--- kw_max_max >  654150.00\n",
      "|   |   |   |   |   |   |   |--- abs_title_sentiment_polarity <= 0.78\n",
      "|   |   |   |   |   |   |   |   |--- value: [4368.67]\n",
      "|   |   |   |   |   |   |   |--- abs_title_sentiment_polarity >  0.78\n",
      "|   |   |   |   |   |   |   |   |--- value: [40050.00]\n",
      "|   |   |   |   |   |--- self_reference_min_shares >  709.00\n",
      "|   |   |   |   |   |   |--- kw_avg_avg <= 5000.05\n",
      "|   |   |   |   |   |   |   |--- value: [144900.00]\n",
      "|   |   |   |   |   |   |--- kw_avg_avg >  5000.05\n",
      "|   |   |   |   |   |   |   |--- kw_avg_min <= 18683.61\n",
      "|   |   |   |   |   |   |   |   |--- n_unique_tokens <= 0.64\n",
      "|   |   |   |   |   |   |   |   |   |--- LDA_01 <= 0.02\n",
      "|   |   |   |   |   |   |   |   |   |   |--- n_non_stop_unique_tokens <= 0.63\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [110200.00]\n",
      "|   |   |   |   |   |   |   |   |   |   |--- n_non_stop_unique_tokens >  0.63\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [3800.00]\n",
      "|   |   |   |   |   |   |   |   |   |--- LDA_01 >  0.02\n",
      "|   |   |   |   |   |   |   |   |   |   |--- avg_positive_polarity <= 0.57\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [7005.68]\n",
      "|   |   |   |   |   |   |   |   |   |   |--- avg_positive_polarity >  0.57\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |--- n_unique_tokens >  0.64\n",
      "|   |   |   |   |   |   |   |   |   |--- n_unique_tokens <= 0.65\n",
      "|   |   |   |   |   |   |   |   |   |   |--- n_unique_tokens <= 0.65\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |   |--- n_unique_tokens >  0.65\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- value: [310800.00]\n",
      "|   |   |   |   |   |   |   |   |   |--- n_unique_tokens >  0.65\n",
      "|   |   |   |   |   |   |   |   |   |   |--- self_reference_avg_sharess <= 4850.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- self_reference_avg_sharess >  4850.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
      "|   |   |   |   |   |   |   |--- kw_avg_min >  18683.61\n",
      "|   |   |   |   |   |   |   |   |--- global_rate_negative_words <= 0.01\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [197600.00]\n",
      "|   |   |   |   |   |   |   |   |--- global_rate_negative_words >  0.01\n",
      "|   |   |   |   |   |   |   |   |   |--- value: [9583.25]\n",
      "|   |--- self_reference_min_shares >  265900.00\n",
      "|   |   |--- average_token_length <= 4.18\n",
      "|   |   |   |--- value: [652900.00]\n",
      "|   |   |--- average_token_length >  4.18\n",
      "|   |   |   |--- self_reference_max_shares <= 475650.00\n",
      "|   |   |   |   |--- value: [106400.00]\n",
      "|   |   |   |--- self_reference_max_shares >  475650.00\n",
      "|   |   |   |   |--- value: [4300.00]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_representation = tree.export_text(dec_tree, feature_names=var_list)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "Program terminated with status: 1. stderr follows: Warning: Could not load \"C:\\Users\\Chaye\\anaconda3\\Library\\bin\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\r\nWarning: Could not load \"C:\\Users\\Chaye\\anaconda3\\Library\\bin\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\r\nFormat: \"pdf\" not recognized. Use one of: bmp canon cmap cmapx cmapx_np dot dot_json emf emfplus eps fig gd gd2 gif gv imap imap_np ismap jpe jpeg jpg json json0 metafile mp pdf pic plain plain-ext png pov ps ps2 svg svg_inline svgz tif tiff tk vrml webp xdot xdot1.2 xdot1.4 xdot_json\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dot_data \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mexport_graphviz(dec_tree, feature_names\u001b[38;5;241m=\u001b[39mvar_list, rounded\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph_from_dot_data(dot_data)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtree.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py:1804\u001b[0m, in \u001b[0;36mDot.__init__.<locals>.<lambda>\u001b[1;34m(path, f, prog)\u001b[0m\n\u001b[0;32m   1794\u001b[0m     f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1795\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m'''Refer to the docstring accompanying the'''\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m''''create' method for more information.'''\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     )\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frmt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformats \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m frmt,\n\u001b[0;32m   1802\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m path,\n\u001b[0;32m   1803\u001b[0m         f\u001b[38;5;241m=\u001b[39mfrmt,\n\u001b[1;32m-> 1804\u001b[0m         prog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1805\u001b[0m     )\n\u001b[0;32m   1807\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m frmt]\n\u001b[0;32m   1808\u001b[0m     f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1809\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m'''Refer to the docstring accompanying the'''\u001b[39;00m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m''''write' method for more information.'''\u001b[39;00m\n\u001b[0;32m   1811\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py:1912\u001b[0m, in \u001b[0;36mDot.write\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1909\u001b[0m         fobj\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m   1911\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1912\u001b[0m         fobj\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1914\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m close:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py:2024\u001b[0m, in \u001b[0;36mDot.create\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   2021\u001b[0m status \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mwait()\n\u001b[0;32m   2023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvocationException(\n\u001b[0;32m   2025\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgram terminated with status: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. stderr follows: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m   2026\u001b[0m             status, stderr_output))\n\u001b[0;32m   2027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stderr_output:\n\u001b[0;32m   2028\u001b[0m     \u001b[38;5;28mprint\u001b[39m(stderr_output)\n",
      "\u001b[1;31mInvocationException\u001b[0m: Program terminated with status: 1. stderr follows: Warning: Could not load \"C:\\Users\\Chaye\\anaconda3\\Library\\bin\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\r\nWarning: Could not load \"C:\\Users\\Chaye\\anaconda3\\Library\\bin\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\r\nFormat: \"pdf\" not recognized. Use one of: bmp canon cmap cmapx cmapx_np dot dot_json emf emfplus eps fig gd gd2 gif gv imap imap_np ismap jpe jpeg jpg json json0 metafile mp pdf pic plain plain-ext png pov ps ps2 svg svg_inline svgz tif tiff tk vrml webp xdot xdot1.2 xdot1.4 xdot_json\r\n"
     ]
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(dec_tree, feature_names=var_list, rounded=True, filled=True)\n",
    "graph = graph_from_dot_data(dot_data)\n",
    "graph.write_pdf('tree.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13- Test the tree you built on the test data by calculating the $ r^2 $ and MSE of the model on the test data: (10 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_hat = dec_tree.predict(X_test)\n",
    "\n",
    "print('test r2:', \"{:.2f}%\".format(r2_score(y_test, y_test_hat)*100))\n",
    "print('test MSE:', \"{:.2f}%\".format(mean_squared_error(y_test, y_test_hat)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14- Comparing your train and test results, do you see any evidence of overfitting? Explain. (10 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on the provided train and test results, there is evidence of overfitting in the model. The high R2 score of 68.81% on the training set suggests a reasonably good fit, but the significantly lower R2 score of -83.21% on the test set indicates poor performance and a lack of generalization. Additionally, the much higher MSE value on the test set compared to the training set further suggests overfitting, as the model's predictions are considerably less accurate on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15- Which variables are the most important ones? Sort and show the input variables based on their importance. (5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'Variable':var_list, 'Importance':dec_tree.feature_importances_}).sort_values(by=['Importance'], ascending=False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16- Why do you think the results of variable importance might not be reliable? (10 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I do not think the results of the variable's importance are reliable, because the models accuracy is not reliable. It is hard to tell if the specific variable is actually important to the output when using a inaccurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Bonus Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17- When the classification counterpart of the problem was analyzed, the results were decent. However, the regression problem yielded poor results. What do you think is the reason? (20 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One possibility is that the regression problem has a higher level of complexity or variability in the target variable, making it more challenging to accurately predict. I think permutation feature selection may be an option to try to get a more accurate linear regression model. Linear regression models are sensitive to noise, so too many variables could be affecting the models accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
